{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ranging-amplifier",
   "metadata": {},
   "source": [
    "# MATH 3375 Examples Notebook #13\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "We explore logistic regression to predict a binary response, starting with the **mtcars** data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data set\n",
    "head(mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-establishment",
   "metadata": {},
   "source": [
    "## Binary Feature: am\n",
    "\n",
    "The **am** column is binary. A value of 0 means the car has an automatic transmission; a value of 1 means it has a manual transmission. According to the summary below, there are 19 cars with automatic transmission, and 13 with manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(as.factor(mtcars$am))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-thickness",
   "metadata": {},
   "source": [
    "#### Another Way to Summarize Binary Data\n",
    "\n",
    "Because the response variable has values that are either 0 or 1, the **_mean_** of the values gives the **_proportion_** of data points where the response variable is 1. In this data set, that tells us the proportion of cars with a manual transmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(mtcars$am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_model0 <- glm(am~1,family=\"binomial\",data=mtcars)\n",
    "summary(tran_model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-usage",
   "metadata": {},
   "source": [
    "### Interpreting the Intercept in a Logistic Model with No Predictors\n",
    "\n",
    "The prediction equation is as follows, where $p$ represents the _**probability the response variable is 1:**_\n",
    "\n",
    "$$g(p) = ln \\left(\\frac{p}{1-p}\\right) = \\widehat{\\beta}_0 = -0.3795$$ \n",
    "\n",
    "Solving for $p$ gives us:\n",
    "\n",
    "$$ p = \\frac{e^{-0.3795}}{1+e^{-0.3795}} \\approx 0.406247 $$\n",
    "\n",
    "This is the same as the value we computed previously as the proportion of cars in the data set with a manual transmission.\n",
    "\n",
    "Because we took no other features into account in this model, the model will simply predict that **_every_** car has a 40.6% chance of having a manual transmission!  We illustrate this by using the model to predict the probability for every row of our original data set.\n",
    "\n",
    "Notice that we use **type=\"response\"** in the predict statement to have the model compute the probability for us. _If this parameter is omitted, the predict function will only give you the log of the odds (in this case, -0.3795)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0_preds <- predict(tran_model0,mtcars,type=\"response\")\n",
    "\n",
    "data.frame(model0_preds, mtcars$am)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-syndrome",
   "metadata": {},
   "source": [
    "### More Useful Models\n",
    "\n",
    "The above model isn't very useful, but it does give us a starting point by illustrating the simplest possible model.\n",
    "\n",
    "Now we look at models where we use one or more features to predict the transmission type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_model1 <- glm(am ~ disp, family=\"binomial\", data=mtcars)\n",
    "summary(tran_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-nursing",
   "metadata": {},
   "source": [
    "#### Interpreting the Model\n",
    "\n",
    "The prediction equation is as follows, where $p$ represents the _**probability the response variable is 1:**_\n",
    "\n",
    "$$g(p) = ln \\left(\\frac{p}{1-p}\\right) = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\times disp = 2.6308 - 0.0146disp$$ \n",
    "\n",
    "Solving for $p$ gives us:\n",
    "\n",
    "$$ p = \\frac{e^{2.6308 - 0.0146disp}}{1+e^{2.6308 - 0.0146disp}} $$\n",
    "\n",
    "\n",
    "#### Visualizing the Model\n",
    "\n",
    "Since we only have one predictor in this model, we can use the above equation to _visualize_ the probabilities over many different possible values of the predictor (**disp**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "points <- seq(0,500,by=0.5)\n",
    "logit_points <- 2.6308 - 0.0146*points\n",
    "prob_points <- exp(logit_points)/(1+exp(logit_points))\n",
    "\n",
    "plot(am~disp,data=mtcars,xlim=c(0,500))\n",
    "points(points,prob_points,col=\"red\",cex=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-academy",
   "metadata": {},
   "source": [
    "### Using the Model\n",
    "\n",
    "This model will give different probabilities for the different cars in the data set, depending on the value of the **disp** feature in each row.  Let's look at how the model performs with our data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_preds <- predict(tran_model1,mtcars,type=\"response\")\n",
    "\n",
    "data.frame(model1_preds, mtcars$am)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-engagement",
   "metadata": {},
   "source": [
    "### Using the Model to Predict Classification\n",
    "\n",
    "To deciding whether the model is useful, we can predict the _**classification**_ for each car (manual or automatic). To do this, we need to pick a threshold. \n",
    "\n",
    "_**How high should the predicted probability be to predict that the car has a manual transmission?**_ To answer this question, we will try a few different thresholds and see which one gives us the best result. \n",
    "\n",
    "It seems natural to try a thrshold of 0.5: Let's say that if the probability is greater than 0.5, we will predict the car has a manual transmission. Otherwise, we predict it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_class_0.5 <- as.integer(model1_preds > 0.5)\n",
    "df_tran_class=data.frame(model1_preds,tran_class_0.5,mtcars$am)\n",
    "df_tran_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-justice",
   "metadata": {},
   "source": [
    "### Summarizing the Model Performance\n",
    "\n",
    "We can create a 'confusion matrix' to summarize how many cars were correctly classified using this threshold and how many were not.\n",
    "\n",
    "**NOTE:** Ideally, we would save a separate test data set to evaluate model performance and compute metrics.  However, **mtcars** is quite small, so we have skipped that step in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted <- tran_class_0.5\n",
    "Actual <- mtcars$am\n",
    "table(Actual,Predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-series",
   "metadata": {},
   "source": [
    "### Model Metrics from the Table\n",
    "\n",
    "The confusion matrix tells us that out of the 19 cars with _automatic_ transmission, 14 were correctly classified (0) and 5 were incorrectly classified. Out of the 13 cars with _manual_ transmission, 11 were correctly classified (1) and 2 were incorrectly classified.\n",
    "\n",
    "Using the confusion matrix, we compute the following classification metrics. \n",
    "\n",
    "Recall that all of these calculations depend on where we choose to set our threshold. For now, we have chosen a threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx <- table(Actual,Predicted)\n",
    "\n",
    "#Row sums: Total actual 'positive' (manual transmission) and actual 'negative' (automatic transmission)\n",
    "ActualPos <- sum(confusion_mtx[2,])\n",
    "ActualNeg <- sum(confusion_mtx[1,])\n",
    "\n",
    "#Column sums: Total PREDICTED positive and negative\n",
    "PredPos <- sum(confusion_mtx[,2])\n",
    "PredNeg <- sum(confusion_mtx[,1])\n",
    "\n",
    "#True Negative and True Positive: Count of CORRECT negative/positive predictions\n",
    "TN <- confusion_mtx[1,1]\n",
    "TP <- confusion_mtx[2,2]\n",
    "\n",
    "#False Negative and False Positive: Count of INCORRECT negative/postivie predictions\n",
    "FP <- confusion_mtx[1,2]\n",
    "FN <- confusion_mtx[2,1]\n",
    "\n",
    "Sensitivity <- TP/ActualPos\n",
    "Specificity <- TN/ActualNeg\n",
    "FalseNegRate <- FN/ActualPos\n",
    "FalsePosRate <- FP/ActualNeg\n",
    "\n",
    "Precision <- TP/PredPos\n",
    "NegativePredValue <- TN/PredNeg\n",
    "\n",
    "Accuracy <- (TP+TN)/(ActualPos+ActualNeg)\n",
    "\n",
    "data.frame(Sensitivity,Specificity,Precision,NegativePredValue,Accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"pROC\")\n",
    "library(pROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_data=roc(Actual, Predicted, quiet=TRUE) \n",
    "plot(roc_data, print.auc=TRUE, main =\"ROC curve - Logistic Regression with Threshold 0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-mechanism",
   "metadata": {},
   "source": [
    "### Adjusting Threshold to Improve the Model\n",
    "\n",
    "Now we will repeat the above steps with multiple thresholds to find the threshold that gives us the highest AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,2))\n",
    "\n",
    "thresh <- c()\n",
    "auc <- c()\n",
    "for (i in 3:8) {\n",
    "    t <- i/10\n",
    "    Predicted <- as.integer(model1_preds > t)\n",
    "    roc_data=roc(Actual, Predicted, quiet=TRUE) \n",
    "    plot(roc_data, print.auc=TRUE, main =paste(\"ROC curve - Threshold\",t))\n",
    "    thresh <- append(thresh,t)\n",
    "    auc <- append(auc,roc_data$auc)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-laundry",
   "metadata": {},
   "source": [
    "### Comparing Model Performance at Different Thresholds\n",
    "\n",
    "We can examine the AUC of our model at the different thresholds in table and graph form below.\n",
    "\n",
    "Of the thresholds tests, 0.4 and 0.5 have the same (highest) performance. For a more thorough analysis, we could try more finely tuned thresholds (such as 0.45, 0.53, etc.) This would be more useful if the data set were larger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.frame(thresh,auc)\n",
    "plot(thresh,auc,xlab=\"Threshold\",ylab=\"AUC\",type=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-coalition",
   "metadata": {},
   "source": [
    "### Calibration Plots\n",
    "\n",
    "Regardless of the threshold selected to predict classification, the original predictions from the model are _**probabilities**_. Another type of evaluation for the model is an analysis of how well those probabilities are calibrated. \n",
    "\n",
    "Suppose several points in the data set have a predicted probability near 20%. This means the model is indicating those points have around a 20% chance of being 'positive' or 1 (in this example, 20% chance of being a manual transmission).  If the model is well calibrated, then of all the points with a predicted probability near 20%, the proportion that **_actually_** are positive should be near 20%.  \n",
    "\n",
    "A **calibration plot** can help us visualize how well calibrated the model's predicted probabilities are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"predtools\")\n",
    "library(predtools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "Probs <- model1_preds\n",
    "df_calibrate <- data.frame(Actual,Probs)\n",
    "calibration_plot(data = df_calibrate, obs = \"Actual\", pred = \"Probs\", title = \"Calibration Plot: Training Data\", \n",
    "                 x_lim=c(0, 0.9), data_summary=TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-suspension",
   "metadata": {},
   "source": [
    "#### Interpreting the Plot\n",
    "\n",
    "* The diagonal line indicates perfect calibration (observed proportion is the same as predicted probability). \n",
    "* Points above the line have higher **_actual_** proportion than predicted; the model's predicted probability was too low.\n",
    "* Points below the line have lower **_actual_** proportion than predicted; the model's predicted probability was too high.\n",
    "* Points are shown with a margin of error (_confidence intervals_); when the margin of error crosses the line, that is an indication that the observed data are highly variable, but the model calibration may still be reasonable.\n",
    "\n",
    "#### Important Notes for This Example\n",
    "\n",
    "* All metrics reported are only for training data. To evaluate a model fully, the same analysis should be conducted with a separate test data set.\n",
    "* The data set used in this example is very small. Therefore, the model is probably not particularly robust, and the metrics provide only very rough estimates of its performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
