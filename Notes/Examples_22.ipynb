{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increasing-vacation",
   "metadata": {},
   "source": [
    "# MATH 3375 Examples Notebook #22\n",
    "\n",
    "# Simple Simulations\n",
    "\n",
    "Using known probability distributions, we first demonstrate a simulation as a way to model expected sales at a coffee shop. \n",
    "\n",
    "## Scenario\n",
    "The arrival rate of customers to a hotel coffee shop between 6:00 and 9:00 a.m. follows a Poisson distribution with an average of 8 customers arriving every 5 minutes.  Thus, measuring time in 1-minute intervals, $\\lambda = \\frac{8}{5}$. \n",
    "\n",
    "Now suppose that the amount spent by each customer follows a normal distribution with a mean of $6.82 and a standard deviation of 98 cents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-snake",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1) What is the projected average total sales at the coffee shop on a given day from 6:00 to 9:00 a.m.?\n",
    "\n",
    "2) What is a 95% confidence interval for average total sales at the coffee shop during these hours?\n",
    "\n",
    "3) What is the probability the total sales during these hours on a given day will be $2000 or more?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-greeting",
   "metadata": {},
   "source": [
    "### Step 1. Set up to use designated probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters for known distributions\n",
    "lambda <- 8/5\n",
    "mean_spend <- 6.82\n",
    "sd_spend <- 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-success",
   "metadata": {},
   "source": [
    "### Step 2. Generate customers\n",
    "\n",
    "First we will simply use the arrival distribution (Poisson with given $\\lambda$) to generate the number of customers arriving each minute during the 3-hour interval. Note that this will be a total of 180 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers <- rpois(180,lambda)\n",
    "print(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-barcelona",
   "metadata": {},
   "source": [
    "### Step 3. Generate amount spent per customer\n",
    "\n",
    "We will use the specified spending distribution (Normal with given $\\mu$ and $\\sigma$) to generate an amount spent by EACH customer for each of the 180 minutes.\n",
    "\n",
    "Notice that in any minute, there can be multiple customers; the variable **c** represents the number of customers that arrive in that minute. Thus, the line \n",
    "\n",
    "    if (c) \n",
    "\n",
    "will be TRUE if c is non-zero, and FALSE when c is zero (no customers during that minute). So we only calculate **spent** if there were customers. Also note that **spent** is a vector of multiple amounts-- one for each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers <- rpois(180,lambda)\n",
    "for (c in customers) {\n",
    "    if (c) {\n",
    "        spent <- round(rnorm(c,mean=mean_spend,sd=sd_spend),2)\n",
    "        #print(spent)\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-wonder",
   "metadata": {},
   "source": [
    "### Step 4. Compute total amount spent \n",
    "\n",
    "Update the above code to keep a running total of the amount spent by each customer.  Since **spent** represents amounts spent by multiple customers in a given minute, we use **sum** to combine them, then add that sum to the total.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "total <- 0\n",
    "\n",
    "customers <- rpois(180,lambda)\n",
    "for (c in customers) {\n",
    "    if (c) {\n",
    "        spent <- round(rnorm(c,mean=mean_spend,sd=sd_spend),2)\n",
    "        total <- total + sum(spent)\n",
    "        }\n",
    "}\n",
    "cat(\"Total spent: \", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-clock",
   "metadata": {},
   "source": [
    "### Step 5. Repetition\n",
    "\n",
    "Above is a single simulation run that gives a value for total spent during the 3-hour period in question.  Is this a good answer to our first question (projected average total sales)?  \n",
    "\n",
    "Run the cell above repeatedly, and you will see many different answers, due to the inherent randomness of generating random values from a distribution. You should notice a lot of variability in the final totals. \n",
    "\n",
    "To get a better estimate of the average total sales, we should run that process many times and use the average of all the results as a much more stable estimate. The code below places the above simulation in a **_loop_** that runs 10,000 times. The **results** vector is used to store the result (total spent) for each of the 10,000 simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "results <- c()\n",
    "\n",
    "for (sim in 1:10000) {\n",
    "    total <- 0\n",
    "\n",
    "    customers <- rpois(180,lambda)\n",
    "    for (c in customers) {\n",
    "        if (c) {\n",
    "            spent <- round(rnorm(c,mean=mean_spend,sd=sd_spend),2)\n",
    "            total <- total + sum(spent)\n",
    "            }\n",
    "    }\n",
    "    results[sim] <- total\n",
    "}\n",
    "\n",
    "head(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-frederick",
   "metadata": {},
   "source": [
    "#### Examine the distribution of simulation results\n",
    "\n",
    "It's useful to look at the distribution of simulation results, both visually and numerically. This is done below. Recall that each result represents the total spent in one simulation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(results)\n",
    "\n",
    "summary(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-fever",
   "metadata": {},
   "source": [
    "### Step 6. Use results to answer questions.\n",
    "\n",
    "##### Q1: What is the projected average total sales at the coffee shop on a given day from 6:00 to 9:00 a.m.?\n",
    "\n",
    "Based on the data summary above, the mean could be reported as a reasonable estimate of average total sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-terrorism",
   "metadata": {},
   "source": [
    "##### Q2: What is a 95% confidence interval for average total sales at the coffee shop during these hours?\n",
    "\n",
    "The middle 95% of the results shown above can be used to create a 95% confidence interval for average total sales. The process is:\n",
    "\n",
    "* Put results in order\n",
    "* Find the **_position_** of the lowest and highest values in the interval.\n",
    "* Use the values in the low/high positions as the lower and upper bounds of the interval.\n",
    "\n",
    "The middle 95% has boundaries to drop the lowest 2.5% and the highest 2.5% of all results. For our 10,000 results, this means we should drop the lowest 250, using 251 for the position of our lower boundary. Then we should drop the highest 250, using 9750 as the position of our upper boundary.\n",
    "\n",
    "This process is carried out below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put results in order\n",
    "results <- sort(results)   \n",
    "\n",
    "#Find position of lower and upper boundaries\n",
    "lower <- round(.025*length(results)) \n",
    "upper <- length(results) - lower\n",
    "\n",
    "#Use results at boundary positions\n",
    "CI_lower <- results[lower+1]\n",
    "CI_upper <- results[upper]\n",
    "\n",
    "paste0(\"95% Confidence Interval: [\",CI_lower,\", \",CI_upper,\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-credit",
   "metadata": {},
   "source": [
    "##### Q3: What is the probability the total sales during these hours on a given day will be $2000 or more?\n",
    "\n",
    "An empirical probability can be computed by counting the number of results with a total of 2000 or more, and then dividing by the total number of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(as.integer(results>=2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(as.integer(results>=2000))/length(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-small",
   "metadata": {},
   "source": [
    "## Identifying the right distribution\n",
    "\n",
    "The above simulations used specific distributions, but where did these come from? Typically some data collection is performed first and these data are used to identify an appropriate distribution. We show this process below, using sample data from recent sales of the coffee shop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_data <- read.csv(\"coffee_spend.csv\")\n",
    "head(spend_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-garlic",
   "metadata": {},
   "source": [
    "First, we look at the sample statistics and plots to visualize the potential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(spend_data$spent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(spend_data$spent)\n",
    "sd(spend_data$spent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-machinery",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The histogram suggests that the normal distribution is **_possibly_** a good fit, and the sample statistics suggest that the distribution would have mean about 6.84 and standard deviation of about 0.99. \n",
    "\n",
    "The plot below can confirm whether the data fit the normal distribution, but it cannot confirm the parameters (mean, sd) of that distribution.  Notice that the theoretical quantiles match the **_standard_** normal distribution (mean=0, sd=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "qqnorm(spend_data$spent)\n",
    "qqline(spend_data$spent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-california",
   "metadata": {},
   "source": [
    "### Create your own QQ Plot for ANY distribution\n",
    "\n",
    "Suppose we want to test our data against a specific distribution with parameters we have defined. Below, we compare our data to a Normal distribution with mean of 6.50 and standard deviation of 0.80.  (This could be the last estimate recorded from several months ago.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(qnorm(seq(0,1,by=.01),mean=6.50,sd=0.80),spend_data$spent,xlab=\"Theoretical Quantiles\")\n",
    "abline(a=0,b=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-error",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "We can see that the $N(6.50,0.80)$ distribution is not a good fit for the data we collected.  However, using the sample values to estimate a $N(6.84,0.99)$ distribution, we can see below that it is a good fit for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(qnorm(seq(0,1,by=.01),mean=6.84,sd=0.99),spend_data$spent,xlab=\"Theoretical Quantiles\")\n",
    "abline(a=0,b=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-symphony",
   "metadata": {},
   "source": [
    "### Testing other distributions\n",
    "\n",
    "Note that the QQ plot is not reserved for normal distributions.  Below we show that the exponential distribution with $\\lambda=0.25$ is also not a good fit for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(qexp(seq(0,1,by=.01),rate=0.25),spend_data$spent,xlab=\"Theoretical Quantiles\")\n",
    "abline(a=0,b=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
