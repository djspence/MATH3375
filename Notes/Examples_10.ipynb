{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ranging-amplifier",
   "metadata": {},
   "source": [
    "# MATH 3375 Examples Notebook #10\n",
    "\n",
    "# Dimension Reduction and Regularization\n",
    "\n",
    "## Elastic Net\n",
    "\n",
    "We continue using the 2004 cars data set to examine Elastic Net, and compare it to LASSO and Ridge Regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data set\n",
    "car_data <- read.csv(\"cars2004.csv\", stringsAsFactors=TRUE)\n",
    "head(car_data,3)\n",
    "tail(car_data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data$Length <- as.integer(as.character(car_data$Length))\n",
    "car_data$Width <- as.integer(as.character(car_data$Width))\n",
    "tail(car_data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data$Length[is.na(car_data$Length)] <- as.integer(median(car_data$Length[!is.na(car_data$Length)]))\n",
    "car_data$Width[is.na(car_data$Width)] <- as.integer(median(car_data$Width[!is.na(car_data$Width)]))\n",
    "head(car_data,3)\n",
    "tail(car_data,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-provision",
   "metadata": {},
   "source": [
    "## 1. Quick Review of LASSO and Ridge Regression\n",
    "\n",
    "LASSO minimizes:\n",
    "\n",
    "$$SSE + \\lambda\\sum_{j=1}^{p}\\left | \\beta_j \\right |$$\n",
    "\n",
    "Ridge Regression computes model coefficients that minimize:\n",
    "\n",
    "$$SSE + \\lambda\\sum_{j=1}^{p} {\\beta_j}^2$$\n",
    "    \n",
    "* LASSO is used for variable selection; Ridge Regression is not. \n",
    "* The constraints in LASSO _**shrink**_ coefficients until some are zero, eliminating the variable from the model.\n",
    "* The constraints in Ridge Regression _account for multicollinearity_ but do not eliminate any variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-establishment",
   "metadata": {},
   "source": [
    "### Implementations with _glmnet_ Library\n",
    "\n",
    "Below we show review basic implementations of LASSO and Ridge Regression with the **glmnet** library.\n",
    "\n",
    "_Only un-comment the install line if the library fails to load. Run the install once and re-comment the line to avoid running the install again._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"glmnet\")\n",
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-screen",
   "metadata": {},
   "source": [
    "#### LASSO Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3375)\n",
    "hp_model_lasso <- cv.glmnet(x=as.matrix(car_data[c(4:7,9:14)]),y=as.matrix(car_data[8]),alpha=1,nfolds=5)\n",
    "coef(hp_model_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-travel",
   "metadata": {},
   "source": [
    "#### Using the LASSO Result\n",
    "\n",
    "The default LASSO model with the most shrinkage (largest acceptable $\\lambda$) has dropped the coefficients for all coefficients except MSRP, EngineSize, Cylinders, and City.MPG.\n",
    "\n",
    "To use these results, we create an OLS model with the predictors that were not dropped by the LASSO model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_model_ols_lasso <- lm(HP ~ MSRP+EngineSize+Cylinders+City.MPG, data=car_data)\n",
    "summary(hp_model_ols_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-letter",
   "metadata": {},
   "source": [
    "#### Ridge Regression Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3375)\n",
    "hp_model_ridge <- cv.glmnet(x=as.matrix(car_data[c(4:7,9:14)]),y=as.matrix(car_data[8]),alpha=0,nfolds=5)\n",
    "coef(hp_model_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-contamination",
   "metadata": {},
   "source": [
    "## 2. Elastic Net\n",
    "\n",
    "Elastic Net is a model that combines the dimension reduction features of LASSO with the improved bias-variance balance of Ridge Regression.\n",
    "\n",
    "Elastic Net coefficients are computed to minimize:\n",
    "\n",
    "$$SSE +  \\alpha \\left(\\lambda\\sum_{j=1}^{p}\\left | \\beta_j \\right |\\right) + (1-\\alpha) \\left(\\lambda\\sum_{j=1}^{p} {\\beta_j}^2 \\right)$$\n",
    "\n",
    "Notice that this is a _combination_ of the LASSO and Ridge penalties, **_weighted_** by the $\\alpha$ value and its complement.\n",
    "\n",
    "In fact, when $\\alpha = 1$, Elastic Net becomes LASSO, and when $\\alpha = 0$, Elastic Net becomes Ridge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-perspective",
   "metadata": {},
   "source": [
    "\n",
    "### Using glmnet for Elastic Net Model\n",
    "\n",
    "Recall that **alpha** was 1 for LASSO and 0 for Ridge.  For Elastic Net, the alpha parameter is somewhere between 0 and 1. The closer **alpha** is to zero, the more heavily weighted the Ridge penalty; the closer **alpha** is to 1, the more heavily weighted the LASSO penalty.  We use values of 0.2, 0.5, and 0.8 below for comparison.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3375)\n",
    "hp_model_elastic1 <- cv.glmnet(x=as.matrix(car_data[c(4:7,9:14)]),y=as.matrix(car_data[8]),alpha=0.2,nfolds=5)\n",
    "plot(hp_model_elastic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3375)\n",
    "hp_model_elastic2 <- cv.glmnet(x=as.matrix(car_data[c(4:7,9:14)]),y=as.matrix(car_data[8]),alpha=0.5,nfolds=5)\n",
    "plot(hp_model_elastic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(3375)\n",
    "hp_model_elastic3 <- cv.glmnet(x=as.matrix(car_data[c(4:7,9:14)]),y=as.matrix(car_data[8]),alpha=0.8,nfolds=5)\n",
    "plot(hp_model_elastic3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-composition",
   "metadata": {},
   "source": [
    "### Coefficients of the Three Elastic Net Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(hp_model_elastic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(hp_model_elastic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(hp_model_elastic3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-intent",
   "metadata": {},
   "source": [
    "### How to Select $\\alpha$?\n",
    "\n",
    "Some possibilities for selecting $\\alpha$ include:\n",
    "\n",
    "* Use 0.5 and equally weight the LASSO and Ridge components.\n",
    "* Use cross-validation with multiple $\\alpha$ values and select the $\\alpha$ that results in the lowest MSE. (Note that the **glmnet** library does NOT do this for you.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-thread",
   "metadata": {},
   "source": [
    "### Predictions from All Models\n",
    "\n",
    "Below we generate predictions of HP for the first 5 rows of our data set, using the Ridge model, all 3 of the Elastic Net models, and the LASSO model. These are displayed (left to right) in increasing order of alpha (0 for Ridge up to 1 for LASSO). \n",
    "\n",
    "For Ridge and Elastic Net, we keep the original model computed by **glmnet**. Recall that for LASSO, it is recommended to use the OLS model with the same predictors that were selected by LASSO. Below, we show the predictions for the original LASSO **_and_** the OLS model with features selected by LASSO, so we can see how they compare.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict HP for first 5 rows of original data set\n",
    "\n",
    "pred_ridge <- predict(hp_model_ridge, newx=as.matrix(car_data[1:5,c(4:7,9:14)]))\n",
    "pred_elastic1 <- predict(hp_model_elastic1, newx=as.matrix(car_data[1:5,c(4:7,9:14)]))\n",
    "pred_elastic2 <- predict(hp_model_elastic2, newx=as.matrix(car_data[1:5,c(4:7,9:14)]))\n",
    "pred_elastic3 <- predict(hp_model_elastic3, newx=as.matrix(car_data[1:5,c(4:7,9:14)]))\n",
    "pred_lasso <- predict(hp_model_lasso, newx=as.matrix(car_data[1:5,c(4:7,9:14)]))\n",
    "pred_ols_lasso <- predict(hp_model_ols_lasso, car_data[1:5,c(4:7,9:14)])\n",
    "\n",
    "df_preds <- data.frame(pred_ridge,pred_elastic1,pred_elastic2,pred_elastic3,pred_lasso,pred_ols_lasso)\n",
    "colnames(df_preds) <- c(\"Ridge\",\"Elastic Net 1\",\"Elastic Net 2\",\"Elastic Net 3\",\"LASSO (Original)\",\"OLS from LASSO\")\n",
    "\n",
    "df_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-mixer",
   "metadata": {},
   "source": [
    "#### Model Comparison\n",
    "\n",
    "Below we compute the MSE for the 5 predictions using each of the 6 models above. Note that **_this is in-sample error only_**. For a better estimate of model performance, we would need to reserve some data in advance as a test set, and create the models with a training data set that excludes the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_ridge <- mean((car_data$HP[1:5] - pred_ridge)^2)\n",
    "MSE_elastic1 <- mean((car_data$HP[1:5] - pred_elastic1)^2)\n",
    "MSE_elastic2 <- mean((car_data$HP[1:5] - pred_elastic2)^2)\n",
    "MSE_elastic3 <- mean((car_data$HP[1:5] - pred_elastic3)^2)\n",
    "MSE_lasso <- mean((car_data$HP[1:5] - pred_lasso)^2)\n",
    "MSE_ols_lasso <- mean((car_data$HP[1:5] - pred_ols_lasso)^2)\n",
    "\n",
    "df_MSE <- data.frame(MSE_ridge,MSE_elastic1,MSE_elastic2,MSE_elastic3,MSE_lasso,MSE_ols_lasso)\n",
    "colnames(df_MSE) <- c(\"Ridge\",\"Elastic Net 1\",\"Elastic Net 2\",\"Elastic Net 3\",\"LASSO (Original)\",\"OLS from LASSO\")\n",
    "\n",
    "df_MSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
